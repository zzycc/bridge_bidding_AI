{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from sys import getsizeof\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import normalize, Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the csv file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n",
      "30000\n",
      "30000\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "######### Use pandas to read \"bridge.csv\",\"combats.csv\" file #########\n",
    "\n",
    "\n",
    "bridge_dfN = pd.read_csv('N.csv')\n",
    "bridge_dfS = pd.read_csv('S.csv')  \n",
    "bridge_dfE = pd.read_csv('E.csv')  \n",
    "bridge_dfW = pd.read_csv('W.csv')\n",
    "\n",
    "#bridge_dfN = pd.DataFrame(df_N)\n",
    "#bridge_dfS = pd.DataFrame(df_S)\n",
    "#bridge_dfE = pd.DataFrame(df_E)\n",
    "#bridge_dfW = pd.DataFrame(df_W)\n",
    "\n",
    "bridge_dfN = bridge_dfN[:30000]\n",
    "bridge_dfS = bridge_dfS[:30000]\n",
    "bridge_dfE = bridge_dfE[:30000]\n",
    "bridge_dfW = bridge_dfW[:30000]\n",
    "\n",
    "bridge_dfN = bridge_dfN.drop('lin_file',axis = 1)\n",
    "bridge_dfN = bridge_dfN.drop('board_num',axis = 1)\n",
    "bridge_dfS = bridge_dfS.drop('lin_file',axis = 1)\n",
    "bridge_dfS = bridge_dfS.drop('board_num',axis = 1)\n",
    "bridge_dfE = bridge_dfE.drop('lin_file',axis = 1)\n",
    "bridge_dfE = bridge_dfE.drop('board_num',axis = 1)\n",
    "bridge_dfW = bridge_dfW.drop('lin_file',axis = 1)\n",
    "bridge_dfW = bridge_dfW.drop('board_num',axis = 1)\n",
    "\n",
    "\n",
    "bridge_dfN['direction'] = 'N'\n",
    "bridge_dfS['direction'] = 'S'\n",
    "bridge_dfE['direction'] = 'E'\n",
    "bridge_dfW['direction'] = 'W'\n",
    "'''\n",
    "bridge_dfN_test = bridge_dfN[500000:505000]\n",
    "bridge_dfS_test = bridge_dfS[500000:505000]\n",
    "bridge_dfE_test = bridge_dfE[500000:505000]\n",
    "bridge_dfW_test = bridge_dfW[500000:505000]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bridge_df = pd.concat([bridge_dfN, bridge_dfS], ignore_index=True)\n",
    "bridge_df = pd.concat([bridge_df, bridge_dfE], ignore_index=True)\n",
    "bridge_df = pd.concat([bridge_df, bridge_dfW], ignore_index=True)\n",
    "#bridge_df = bridge_df.astype('int')\n",
    "#df = pd.read_csv('combats.csv') \n",
    "#combats_df = df\n",
    "#print(combats_df.iloc[:,:])\n",
    "#print(len(combats_df.iloc[:,:]))\n",
    "print(len(bridge_dfN.iloc[:,:]))\n",
    "print(len(bridge_dfS.iloc[:,:]))\n",
    "print(len(bridge_dfE.iloc[:,:]))\n",
    "print(len(bridge_dfW.iloc[:,:]))\n",
    "\n",
    "print(len(bridge_df.iloc[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "aaa = [1, 2, 3]\n",
    "bbb = [4, 5, 6]\n",
    "test.append(aaa)\n",
    "test.append(bbb)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(bridge_dfW)  #set seq = 30num\n",
    "\n",
    "train_data = []\n",
    "train_data_without_feature = []\n",
    "\n",
    "for i in range(len(bridge_df.iloc[:,:])):\n",
    "    if bridge_df.iloc[i,1] == 'none':\n",
    "        bridge_df.iloc[i,1] = 0\n",
    "    elif bridge_df.iloc[i,1] == 'NS':\n",
    "        bridge_df.iloc[i,1] = 1\n",
    "    elif bridge_df.iloc[i,1] == 'EW':\n",
    "        bridge_df.iloc[i,1] = 2\n",
    "    elif bridge_df.iloc[i,1] == 'both':\n",
    "        bridge_df.iloc[i,1] = 3\n",
    "    \n",
    "    temp_list = []\n",
    "    without_feature = []\n",
    "    temp_list.append(bridge_df.iloc[i,0])\n",
    "    without_feature.append(bridge_df.iloc[i,0])\n",
    "    temp_list.append(bridge_df.iloc[i,1])\n",
    "    without_feature.append(bridge_df.iloc[i,1])\n",
    "    temp_list.append(bridge_df.iloc[i,2])\n",
    "    without_feature.append(bridge_df.iloc[i,2])\n",
    "    temp_list.append(bridge_df.iloc[i,3])\n",
    "    without_feature.append(bridge_df.iloc[i,3])\n",
    "    temp_list.append(bridge_df.iloc[i,5])\n",
    "    without_feature.append(bridge_df.iloc[i,5])\n",
    "\n",
    "    split_list6 = bridge_df.iloc[i,6].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list6[j])\n",
    "    '''\n",
    "    split_list7 = bridge_df.iloc[i,7].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list7[j])\n",
    "    '''\n",
    "    split_list9 = bridge_df.iloc[i,9].split('|')    \n",
    "    for j in range(4):\n",
    "        suit = [0]*13\n",
    "        for k in range(len(split_list9[j])):\n",
    "            if split_list9[j][k] == 'A':\n",
    "                suit[1] = 1\n",
    "            elif split_list9[j][k] == 'K':\n",
    "                suit[0] = 1\n",
    "            elif split_list9[j][k] == 'Q':\n",
    "                suit[12] = 1\n",
    "            elif split_list9[j][k] == 'J':\n",
    "                suit[11] = 1\n",
    "            elif split_list9[j][k] == 'T':\n",
    "                suit[10] = 1\n",
    "            elif split_list9[j][k].isdigit():\n",
    "                suit[int(split_list9[j][k])] = 1\n",
    "            else:\n",
    "                suit[k] = -1\n",
    "        without_feature = without_feature + suit\n",
    "        temp_list = temp_list + suit\n",
    "\n",
    "    split_list10 = bridge_df.iloc[i,10].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list10[j])\n",
    "    temp_list.append(bridge_df.iloc[i,11])\n",
    "\n",
    "    split_list12 = bridge_df.iloc[i,12].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list12[j])\n",
    "    split_list13 = bridge_df.iloc[i,13].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list13[j])\n",
    "    split_list14 = bridge_df.iloc[i,14].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list14[j])\n",
    "    split_list15 = bridge_df.iloc[i,15].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list15[j])\n",
    "\n",
    "    temp_list.append(bridge_df.iloc[i,16])\n",
    "    temp_list.append(bridge_df.iloc[i,17])\n",
    "    if(bridge_df.iloc[i,18] == 'N'):\n",
    "        temp_list.append(0)\n",
    "    elif(bridge_df.iloc[i,18] == 'S'):\n",
    "        temp_list.append(1)\n",
    "    elif(bridge_df.iloc[i,18] == 'E'):\n",
    "        temp_list.append(2)\n",
    "    elif(bridge_df.iloc[i,18] == 'W'):\n",
    "        temp_list.append(3)\n",
    "    else:\n",
    "        temp_list.append(-1)\n",
    "        \n",
    "    order = bridge_df.iloc[i,5]\n",
    "    #print('order:', order)\n",
    "    split_list = bridge_df.iloc[i,4].split('|')\n",
    "    #print('len: ', len(split_list))\n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence\n",
    "    #example = []\n",
    "    \n",
    "    for ex in range(add_bidding):\n",
    "        temp = 0\n",
    "        temp_list_bidding =[-1]*12\n",
    "        end_1 = ex*4 + order - 1 # split_list[end_1] is the bidding choice of this player in this round \n",
    "        #print('end_1: ', end_1)\n",
    "        #lenth_1 = len(split_list)-1\n",
    "        for j in range(end_1):\n",
    "            if(j>11):\n",
    "                break\n",
    "            split_list[end_1-j-1] = split_list[end_1-j-1].replace(\"!\", \"\")\n",
    "            #print(split_list[end_1-j-1])\n",
    "            if(split_list[end_1-j-1][0]=='p' or split_list[end_1-j-1][0]=='P'):\n",
    "                temp_list_bidding[11-j]=0\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='d' or split_list[end_1-j-1][0]=='D'):\n",
    "                temp_list_bidding[11-j]=36\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='r' or split_list[end_1-j-1][0]=='R'):\n",
    "                temp_list_bidding[11-j]=37\n",
    "                continue\n",
    "\n",
    "\n",
    "            temp = 0\n",
    "            if(len(split_list[end_1-j-1]) != 2):\n",
    "                temp = -1\n",
    "                break\n",
    "            if(split_list[end_1-j-1][0].isdigit()):\n",
    "                temp += (int(split_list[end_1-j-1][0])-1)*5\n",
    "            if(split_list[end_1-j-1][1] == 'C' or split_list[end_1-j-1][1] == 'c'):\n",
    "                temp += 1\n",
    "            elif(split_list[end_1-j-1][1] == 'D' or split_list[end_1-j-1][1] == 'd' ):\n",
    "                temp += 2\n",
    "            elif(split_list[end_1-j-1][1] == 'H' or split_list[end_1-j-1][1] == 'h'):\n",
    "                temp += 3\n",
    "            elif(split_list[end_1-j-1][1] == 'S' or split_list[end_1-j-1][1] == 's'):\n",
    "                temp += 4\n",
    "            elif(split_list[end_1-j-1][1] == 'N' or split_list[end_1-j-1][1] == 'n'):\n",
    "                temp += 5\n",
    "            else:\n",
    "                temp = -1\n",
    "                break\n",
    "            temp_list_bidding[11-j] = temp\n",
    "            \n",
    "        example = temp_list.copy()\n",
    "        example_without_fea =  without_feature.copy()\n",
    "        for j in range(12):\n",
    "            example.append(temp_list_bidding[j])\n",
    "            example_without_fea.append(temp_list_bidding[j])\n",
    "        train_data.append(example)\n",
    "        train_data_without_feature.append(example_without_fea)\n",
    "        \n",
    "train_data = np.asarray(train_data)\n",
    "train_data_without_feature = np.asarray(train_data_without_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float')\n",
    "train_data_without_feature = train_data_without_feature.astype('float')\n",
    "#np.savetxt('./data/train_data_savefile_back12_orig_30000.txt', train_data, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = train_data.copy()\n",
    "train_without_feature_orig = train_data_without_feature.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig_2 = train_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = np.loadtxt('./data/train_data_savefile_back12_orig_30000.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.   0.   9.   0.   0. ]\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.   0.   9.   0.   0. ]\n"
     ]
    }
   ],
   "source": [
    "print(train_orig[0])\n",
    "print(train_orig[1])\n",
    "#print(train_orig_2[0])\n",
    "#print(train_orig_2[1])\n",
    "print(train_data[0])\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05847053  0.          0.          0.          0.05847053  0.1754116\n",
      "   0.1754116   0.23388214  0.1754116   0.          0.          0.\n",
      "   0.          0.          0.05847053  0.05847053  0.          0.\n",
      "   0.          0.          0.05847053  0.          0.          0.05847053\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.05847053  0.05847053  0.\n",
      "   0.          0.          0.          0.05847053  0.          0.05847053\n",
      "   0.05847053  0.          0.          0.          0.          0.05847053\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.05847053  0.05847053  0.          0.          0.          0.\n",
      "   0.05847053  0.05847053  0.40929374  0.11694107  0.11694107  0.70164642\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.14617634  0.05847053  0.          0.20464687  0.05847053\n",
      "   0.         -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053\n",
      "  -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053\n",
      "  -0.05847053]]\n",
      "[ 0.05847053  0.          0.          0.          0.05847053  0.1754116\n",
      "  0.1754116   0.23388214  0.1754116   0.          0.          0.\n",
      "  0.          0.          0.05847053  0.05847053  0.          0.\n",
      "  0.          0.          0.05847053  0.          0.          0.05847053\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.05847053  0.05847053  0.\n",
      "  0.          0.          0.          0.05847053  0.          0.05847053\n",
      "  0.05847053  0.          0.          0.          0.          0.05847053\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.05847053  0.05847053  0.          0.          0.          0.\n",
      "  0.05847053  0.05847053  0.40929374  0.11694107  0.11694107  0.70164642\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.14617634  0.05847053  0.          0.20464687  0.05847053\n",
      "  0.         -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053\n",
      " -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053\n",
      " -0.05847053]\n",
      "[[ 0.628779    0.03493217  0.03493217  0.          0.06986433  0.17466083\n",
      "   0.13972867  0.06986433  0.06986433  0.          0.03493217  0.03493217\n",
      "   0.          0.          0.          0.03493217  0.          0.\n",
      "   0.03493217  0.          0.          0.03493217  0.          0.\n",
      "   0.03493217  0.          0.          0.03493217  0.          0.\n",
      "   0.          0.03493217  0.03493217  0.          0.          0.03493217\n",
      "   0.          0.          0.03493217  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.03493217  0.          0.          0.          0.          0.\n",
      "   0.03493217  0.209593    0.          0.1047965   0.06986433  0.38425383\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.03493217  0.          0.          0.\n",
      "   0.08733042  0.03493217  0.01746608  0.          0.13972867  0.03493217\n",
      "   0.03493217 -0.03493217 -0.03493217 -0.03493217 -0.03493217 -0.03493217\n",
      "  -0.03493217 -0.03493217  0.          0.13972867  0.27945733  0.419186\n",
      "   0.        ]]\n",
      "[ 0.628779    0.03493217  0.03493217  0.          0.06986433  0.17466083\n",
      "  0.13972867  0.06986433  0.06986433  0.          0.03493217  0.03493217\n",
      "  0.          0.          0.          0.03493217  0.          0.\n",
      "  0.03493217  0.          0.          0.03493217  0.          0.\n",
      "  0.03493217  0.          0.          0.03493217  0.          0.\n",
      "  0.          0.03493217  0.03493217  0.          0.          0.03493217\n",
      "  0.          0.          0.03493217  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.03493217  0.          0.          0.          0.          0.\n",
      "  0.03493217  0.209593    0.          0.1047965   0.06986433  0.38425383\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.03493217  0.          0.          0.\n",
      "  0.08733042  0.03493217  0.01746608  0.          0.13972867  0.03493217\n",
      "  0.03493217 -0.03493217 -0.03493217 -0.03493217 -0.03493217 -0.03493217\n",
      " -0.03493217 -0.03493217  0.          0.13972867  0.27945733  0.419186\n",
      "  0.        ]\n",
      "Normalizer(copy=True, norm='l2')\n",
      "(341553, 97)\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[18.   1.   1.   0.   2.   5.   4.   2.   2.   0.   1.   1.   0.   0.\n",
      "  0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   1.   0.   0.   1.\n",
      "  0.   0.   0.   1.   1.   0.   0.   1.   0.   0.   1.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "  0.   0.   0.   0.   1.   6.   0.   3.   2.  11.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   1.   0.   0.   0.   2.5  1.   0.5  0.   4.   1.\n",
      "  1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.   0.   4.   8.  12.   0. ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_data = normalize(train_data, axis=0, norm='l2')\n",
    "normalizer = Normalizer(norm='l2').fit(train_data)\n",
    "train_norm = normalizer.transform(train_data)\n",
    "print(normalizer.transform(train_data[0].reshape(1, -1)))\n",
    "print(train_norm[0])\n",
    "print(normalizer.transform(train_data[115000].reshape(1, -1)))\n",
    "print(train_norm[115000])\n",
    "print(normalizer)\n",
    "print(train_data.shape)\n",
    "print(train_data[0])\n",
    "print(train_data[115000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19245009  0.          0.          0.          0.19245009  0.\n",
      "   0.          0.          0.          0.          0.19245009  0.19245009\n",
      "   0.          0.          0.          0.          0.19245009  0.\n",
      "   0.          0.19245009  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.19245009\n",
      "   0.19245009  0.          0.          0.          0.          0.19245009\n",
      "   0.          0.19245009  0.19245009  0.          0.          0.\n",
      "   0.          0.19245009  0.          0.          0.          0.\n",
      "   0.          0.          0.19245009  0.19245009  0.          0.\n",
      "   0.          0.          0.19245009 -0.19245009 -0.19245009 -0.19245009\n",
      "  -0.19245009 -0.19245009 -0.19245009 -0.19245009 -0.19245009 -0.19245009\n",
      "  -0.19245009 -0.19245009 -0.19245009]]\n",
      "[ 0.19245009  0.          0.          0.          0.19245009  0.\n",
      "  0.          0.          0.          0.          0.19245009  0.19245009\n",
      "  0.          0.          0.          0.          0.19245009  0.\n",
      "  0.          0.19245009  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.19245009\n",
      "  0.19245009  0.          0.          0.          0.          0.19245009\n",
      "  0.          0.19245009  0.19245009  0.          0.          0.\n",
      "  0.          0.19245009  0.          0.          0.          0.\n",
      "  0.          0.          0.19245009  0.19245009  0.          0.\n",
      "  0.          0.          0.19245009 -0.19245009 -0.19245009 -0.19245009\n",
      " -0.19245009 -0.19245009 -0.19245009 -0.19245009 -0.19245009 -0.19245009\n",
      " -0.19245009 -0.19245009 -0.19245009]\n",
      "[[ 0.75130548  0.04173919  0.04173919  0.          0.08347839  0.\n",
      "   0.04173919  0.04173919  0.          0.          0.          0.04173919\n",
      "   0.          0.          0.04173919  0.          0.          0.04173919\n",
      "   0.          0.          0.04173919  0.          0.          0.04173919\n",
      "   0.          0.          0.          0.04173919  0.04173919  0.\n",
      "   0.          0.04173919  0.          0.          0.04173919  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.04173919  0.          0.          0.\n",
      "   0.          0.          0.04173919 -0.04173919 -0.04173919 -0.04173919\n",
      "  -0.04173919 -0.04173919 -0.04173919 -0.04173919  0.          0.16695677\n",
      "   0.33391355  0.50087032  0.        ]]\n",
      "[ 0.75130548  0.04173919  0.04173919  0.          0.08347839  0.\n",
      "  0.04173919  0.04173919  0.          0.          0.          0.04173919\n",
      "  0.          0.          0.04173919  0.          0.          0.04173919\n",
      "  0.          0.          0.04173919  0.          0.          0.04173919\n",
      "  0.          0.          0.          0.04173919  0.04173919  0.\n",
      "  0.          0.04173919  0.          0.          0.04173919  0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.04173919  0.          0.          0.\n",
      "  0.          0.          0.04173919 -0.04173919 -0.04173919 -0.04173919\n",
      " -0.04173919 -0.04173919 -0.04173919 -0.04173919  0.          0.16695677\n",
      "  0.33391355  0.50087032  0.        ]\n",
      "Normalizer(copy=True, norm='l2')\n",
      "(341553, 69)\n",
      "[ 1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.\n",
      "  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "  0.  0.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[18.  1.  1.  0.  2.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  1. -1. -1. -1. -1. -1. -1. -1.  0.  4.  8. 12.  0.]\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='l2').fit(train_data_without_feature)\n",
    "train_without_feature_norm = normalizer.transform(train_data_without_feature)\n",
    "print(normalizer.transform(train_data_without_feature[0].reshape(1, -1)))\n",
    "print(train_without_feature_norm[0])\n",
    "print(normalizer.transform(train_data_without_feature[115000].reshape(1, -1)))\n",
    "print(train_without_feature_norm[115000])\n",
    "print(normalizer)\n",
    "print(train_data_without_feature.shape)\n",
    "print(train_data_without_feature[0])\n",
    "print(train_data_without_feature[115000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_org = train_data\n",
    "train_data_backup = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.000e-05  0.000e+00  0.000e+00  0.000e+00  6.500e-04  1.456e-03\n",
      "  1.454e-03  1.938e-03  1.452e-03  0.000e+00  0.000e+00  0.000e+00\n",
      "  0.000e+00  0.000e+00  3.419e-03  3.415e-03  0.000e+00  0.000e+00\n",
      "  0.000e+00  0.000e+00  3.426e-03  0.000e+00  0.000e+00  3.448e-03\n",
      "  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  0.000e+00  0.000e+00  0.000e+00  3.421e-03  3.429e-03  0.000e+00\n",
      "  0.000e+00  0.000e+00  0.000e+00  3.415e-03  0.000e+00  3.416e-03\n",
      "  3.416e-03  0.000e+00  0.000e+00  0.000e+00  0.000e+00  3.432e-03\n",
      "  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  3.417e-03  3.418e-03  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  3.425e-03  5.040e-04  3.527e-03  1.008e-03  1.005e-03  1.904e-03\n",
      "  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  0.000e+00  2.254e-03  9.010e-04  0.000e+00  1.128e-03  1.319e-03\n",
      "  0.000e+00 -6.140e-04 -4.840e-04 -4.400e-04 -3.570e-04 -3.250e-04\n",
      " -2.670e-04 -2.470e-04 -2.130e-04 -2.040e-04 -1.700e-04 -1.710e-04\n",
      " -1.710e-04]\n",
      "[ 0.002247  0.000909  0.002412  0.        0.0013    0.001456  0.000969\n",
      "  0.001454  0.00242   0.003442  0.        0.        0.003418  0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.003427  0.        0.        0.        0.003419  0.        0.\n",
      "  0.00342   0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.003415  0.00342   0.\n",
      "  0.        0.        0.        0.        0.        0.003432  0.003436\n",
      "  0.003449  0.003413  0.003418  0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.003425  0.002518  0.\n",
      "  0.001008  0.004524  0.002539  0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.00401   0.001427  0.        0.        0.004473  0.002096  0.001319\n",
      "  0.       -0.000614 -0.000484 -0.00044  -0.000357 -0.000325 -0.000267\n",
      " -0.000247  0.001063  0.007344  0.001193  0.        0.001365]\n",
      "[[ 8.000e-05  0.000e+00  0.000e+00 ... -1.700e-04 -1.710e-04 -1.710e-04]\n",
      " [ 8.000e-05  0.000e+00  0.000e+00 ...  1.534e-03  0.000e+00  0.000e+00]\n",
      " [ 8.000e-05  0.000e+00  0.000e+00 ... -1.700e-04 -1.710e-04 -1.710e-04]\n",
      " ...\n",
      " [ 3.210e-04  2.728e-03  2.412e-03 ...  5.110e-04  2.387e-03  2.900e-03]\n",
      " [ 3.210e-04  2.728e-03  2.412e-03 ...  3.239e-03  0.000e+00  3.412e-03]\n",
      " [ 3.210e-04  2.728e-03  2.412e-03 ...  4.091e-03  0.000e+00  4.777e-03]]\n",
      "(341553, 97)\n"
     ]
    }
   ],
   "source": [
    "#np.savetxt('./data/train_data_savefile_back12_30000.txt', train_data, fmt='%f')\n",
    "train_data = []\n",
    "train_data = np.loadtxt('./data/train_data_savefile_back12_30000.txt', dtype=float)\n",
    "print(train_data[0])\n",
    "print(train_data[999])\n",
    "print(train_data)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data[:,0] = train_data[:,0]/50\n",
    "train_data[:,1] = train_data[:,1]/3\n",
    "train_data[:,4:15] = train_data[:,4:15]/37\n",
    "train_data[:,16] = train_data[:,16]/4\n",
    "train_data[:,17:20] = train_data[:,17:20]/13\n",
    "train_data[:,73:76] = train_data[:,73:76]/13\n",
    "train_data[:,81] = train_data[:,81]/30\n",
    "train_data[:,91:94] = train_data[:,91:94]/10\n",
    "train_data[:,95] = train_data[:,95]/10\n",
    "train_data[:,96] = train_data[:,96]/10\n",
    "'''\n",
    "train_data[:,0] = train_data[:,0]*50\n",
    "train_data[:,1] = train_data[:,1]*3\n",
    "train_data[:,4] = train_data[:,4]*2000\n",
    "train_data[:,5] = train_data[:,5]*4\n",
    "train_data[:,6:13] = train_data[:,6:13]*13\n",
    "train_data[:,66:69] = train_data[:,66:69]*13\n",
    "train_data[:,70] = train_data[:,70]*30\n",
    "train_data[:,83:86] = train_data[:,83:86]*10\n",
    "train_data[:,87] = train_data[:,87]*10\n",
    "'''\n",
    "print(train_data[0,:])\n",
    "print(train_data)\n",
    "print(train_data.shape)\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make one-hot format labels (But bridge seems to use 13-hot-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "341553\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "#train_labels[i][1]:\n",
    "#combats_df.iloc[:,2]\n",
    "\n",
    "combats_train_hot_label = [[0 for x in range(38)] for y in range(len(train_data))]\n",
    "print(type(combats_train_hot_label))\n",
    "t = 0\n",
    "\n",
    "for i in range(len(bridge_df.iloc[:,:])):\n",
    "    split_list = bridge_df.iloc[i,4].split('|')\n",
    "    order = bridge_df.iloc[i,5]\n",
    "    \n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence\n",
    "    #print('len:', len(split_list), 'order', order)\n",
    "    #if(order+1>len(split_list)):\n",
    "        #combats_train_hot_label[i][35] = 1\n",
    "        #continue\n",
    "        \n",
    "    for ex in range(add_bidding):\n",
    "        end_1 = ex*4 + order - 1\n",
    "        #print(end_1)\n",
    "        split_list[end_1] = split_list[end_1].replace(\"!\", \"\")\n",
    "        if(split_list[end_1]=='p' or split_list[end_1]=='p!' or split_list[end_1]=='P' or split_list[end_1]=='P!'):\n",
    "            combats_train_hot_label[t][0] = 1\n",
    "\n",
    "        elif(split_list[end_1]=='d' or split_list[end_1]=='d!' or split_list[end_1]=='D' or split_list[end_1]=='D!'):\n",
    "            combats_train_hot_label[t][36] = 1\n",
    "        elif(split_list[end_1]=='r' or split_list[end_1]=='r!' or split_list[end_1]=='R' or split_list[end_1]=='R!'):\n",
    "            combats_train_hot_label[t][37] = 1\n",
    "        temp_num = 0    \n",
    "        if (len(split_list[end_1]) == 2 and split_list[end_1][0].isdigit()):\n",
    "            temp_num = (int(split_list[end_1][0])-1)*5\n",
    "            if(split_list[end_1][1] == 'C' or split_list[end_1][1] == 'c'):\n",
    "                temp_num += 1\n",
    "            elif(split_list[end_1][1] == 'D' or split_list[end_1][1] == 'd' ):\n",
    "                temp_num += 2\n",
    "            elif(split_list[end_1][1] == 'H' or split_list[end_1][1] == 'h'):\n",
    "                temp_num += 3\n",
    "            elif(split_list[end_1][1] == 'S' or split_list[end_1][1] == 's'):\n",
    "                temp_num += 4\n",
    "            elif(split_list[end_1][1] == 'N' or split_list[end_1][1] == 'n'): \n",
    "                temp_num += 5\n",
    "            else:\n",
    "                temp_num = 0\n",
    "            combats_train_hot_label[t][temp_num] = 1 \n",
    "        t += 1\n",
    "    \n",
    "\n",
    "#combats_train_hot_label = np_utils.to_categorical(combats_train_label,2)\n",
    "\n",
    "combats_train_hot_label = np.asarray(combats_train_hot_label)\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "(341553, 38)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(combats_train_hot_label[114998][:])\n",
    "print(combats_train_hot_label[114999][:])\n",
    "print(combats_train_hot_label[115000][:])\n",
    "print(combats_train_hot_label)\n",
    "print(combats_train_hot_label.shape)\n",
    "print(type(combats_train_hot_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "(341553, 38)\n"
     ]
    }
   ],
   "source": [
    "#np.savetxt('./data/combats_train_hot_label_save_file_back12_30000.txt', combats_train_hot_label, fmt='%d')\n",
    "combats_train_hot_label = np.loadtxt('./data/combats_train_hot_label_save_file_back12_30000.txt', dtype=int)\n",
    "print(combats_train_hot_label[0])\n",
    "print(combats_train_hot_label[999])\n",
    "print(combats_train_hot_label)\n",
    "print(combats_train_hot_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115001, 38)\n",
      "<class 'numpy.ndarray'>\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#combats_train_hot_label = to_categorical(combats_train_hot_label,2)\n",
    "#combats_train_hot_label = combats_train_hot_label.astype(float)\n",
    "print(combats_train_hot_label.shape)\n",
    "print(type(combats_train_hot_label))\n",
    "print(combats_train_hot_label[0,:])\n",
    "print(combats_train_hot_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Embedding\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    ###   code here  #####\n",
    "    #keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\n",
    "    \n",
    "    model.add(Dense(128,input_shape = (97,))) #need to check the input size, first set the input node to be 128 as matlab do\n",
    "    model.add(Activation('relu')) #might be leakyRelu, since they used the parameter alpha, still need to check\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.8))\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.8))\n",
    "    \"\"\" \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.8))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.8))\n",
    "    \"\"\"   \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.8))\n",
    "\n",
    "    model.add(Dense(38,activation='softmax')) #need to check the output size, seems to be 36\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_259 (Dense)            (None, 128)               12544     \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 38)                4902      \n",
      "=================================================================\n",
      "Total params: 85,414\n",
      "Trainable params: 84,390\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Train on 307397 samples, validate on 34156 samples\n",
      "Epoch 1/1000\n",
      "307397/307397 [==============================] - 11s 36us/step - loss: 1.9365 - acc: 0.5698 - val_loss: 1.6423 - val_acc: 0.6377\n",
      "Epoch 2/1000\n",
      "307397/307397 [==============================] - 1s 5us/step - loss: 1.3288 - acc: 0.6539 - val_loss: 1.6247 - val_acc: 0.6315\n",
      "Epoch 3/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.2072 - acc: 0.6668 - val_loss: 1.4317 - val_acc: 0.6355\n",
      "Epoch 4/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.1507 - acc: 0.6730 - val_loss: 1.3262 - val_acc: 0.6389\n",
      "Epoch 5/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.1101 - acc: 0.6783 - val_loss: 1.2204 - val_acc: 0.6502\n",
      "Epoch 6/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.0814 - acc: 0.6828 - val_loss: 1.2386 - val_acc: 0.6427\n",
      "Epoch 7/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.0589 - acc: 0.6864 - val_loss: 1.2065 - val_acc: 0.6584\n",
      "Epoch 8/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.0385 - acc: 0.6905 - val_loss: 1.2507 - val_acc: 0.6381\n",
      "Epoch 9/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.0254 - acc: 0.6924 - val_loss: 1.2512 - val_acc: 0.6442\n",
      "Epoch 10/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 1.0088 - acc: 0.6962 - val_loss: 1.1697 - val_acc: 0.6481\n",
      "Epoch 11/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 0.9992 - acc: 0.6970 - val_loss: 1.1971 - val_acc: 0.6381\n",
      "Epoch 12/1000\n",
      "307397/307397 [==============================] - 2s 5us/step - loss: 0.9858 - acc: 0.7002 - val_loss: 1.1823 - val_acc: 0.6441\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "############## Start Training ############\n",
    "# use validation_data=(valid_data,valid_labels) in model.fit !!!!!! #\n",
    "'''\n",
    "training parameters\n",
    "update_dnntype = 2; \n",
    "badupdate_dnn = 2; \n",
    "explore_first = 1; \n",
    "alphaupdate_dnn = 0.1;\n",
    "batchsizeupdate_dnn = 50;\n",
    "batchsize = 50;\n",
    "decayRate = 0.98;\n",
    "momentum = 0.82;\n",
    "alpha = 0.83;\n",
    "startbackprop = 0;\n",
    "input = 52+36+5;\n",
    "lsize = 128;\n",
    "layer = 4;\n",
    "output = 36;\n",
    "eta = 0.05;\n",
    "'''\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "model = build_model()\n",
    "#sgd = optimizers.SGD(lr=0.2, clipnor0m=1.0,decay = 1e-08) #original 1e-08)\n",
    "#adadelta = optimizers.Adadelta(lr=1.0, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=\"adadelta\"#\"adadelta\"\n",
    "            ,loss='categorical_crossentropy'\n",
    "            #,loss='mae'\n",
    "            ,metrics=['accuracy'])\n",
    "\n",
    "record = model.fit(train_norm,combats_train_hot_label\n",
    "                   ,batch_size=4096 #original 64\n",
    "                   ,epochs=1000\n",
    "                   ,validation_split = 0.1\n",
    "                   ,callbacks=[earlyStopping]\n",
    "                   ,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56666/56666 [==============================] - 0s 6us/step\n",
      "Test score: 1.1906474204883528\n",
      "Test acc: 0.6379663289672499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(28338):    check = True\\n    while(check):\\n        check = False\\n        for j in range(int(avoid_data[i][16])-1):\\n            if(pred[i]>=1 and pred[i]<=35):\\n                if(avoid_data[i][j]>pred[i] and avoid_data[i][j]>=1 and avoid_data[i][j]<=35):\\n                    pred_array[i][pred[i]] = 0\\n                    pred[i] = np.argmax(pred_array[i])\\n                    check = True\\n            else:\\n                if(avoid_data[i][j]>pred[i] and (avoid_data[i][j]==36 or avoid_data[i][j]==37)):\\n                    pred_array[i][pred[i]] = 0\\n                    pred[i] = np.argmax(pred_array[i])\\n                    check = True\\n\\n\\ncount = 0\\nfor i in range(28338):\\n    if(pred[i][0]==np.argmax(combats_test_hot_label[i])):\\n        count+=1\\n\\nprint(count/28338)#the test accuracy\\nprint(count)\\n\\n\\nfor i in range(test_data):\\n    pred[i] = np.argmax(model.predict(test_data[i])[前一家叫牌:], axis=1)\\n'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### use \"model.predict(testing_data)\" to get the results ######\n",
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('bridge_model.h5')\n",
    "#pred = np.argmax(model.predict(test_data), axis=1).reshape(len(test_data),1)\n",
    "#pred_array = model.predict(test_data)\n",
    "#predicted_output_df = pd.DataFrame(pred, columns = [\"card output\"])  #predicted output\n",
    "#output = pd.read_csv('bridge_test_output1.csv') #real ouput\n",
    "score, acc = model.evaluate(test_norm, combats_test_hot_label, batch_size=1024)\n",
    "print('Test score:', score)\n",
    "print('Test acc:', acc)\n",
    "#print(pred)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(28338):    check = True\n",
    "    while(check):\n",
    "        check = False\n",
    "        for j in range(int(avoid_data[i][16])-1):\n",
    "            if(pred[i]>=1 and pred[i]<=35):\n",
    "                if(avoid_data[i][j]>pred[i] and avoid_data[i][j]>=1 and avoid_data[i][j]<=35):\n",
    "                    pred_array[i][pred[i]] = 0\n",
    "                    pred[i] = np.argmax(pred_array[i])\n",
    "                    check = True\n",
    "            else:\n",
    "                if(avoid_data[i][j]>pred[i] and (avoid_data[i][j]==36 or avoid_data[i][j]==37)):\n",
    "                    pred_array[i][pred[i]] = 0\n",
    "                    pred[i] = np.argmax(pred_array[i])\n",
    "                    check = True\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(28338):\n",
    "    if(pred[i][0]==np.argmax(combats_test_hot_label[i])):\n",
    "        count+=1\n",
    "\n",
    "print(count/28338)#the test accuracy\n",
    "print(count)\n",
    "\n",
    "\n",
    "for i in range(test_data):\n",
    "    pred[i] = np.argmax(model.predict(test_data[i])[前一家叫牌:], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [13]\n",
      " [28]\n",
      " [28]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [28]\n",
      " [28]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [30]\n",
      " [27]\n",
      " [27]\n",
      " [28]\n",
      " [ 6]\n",
      " [18]\n",
      " [36]\n",
      " [ 6]\n",
      " [23]\n",
      " [36]\n",
      " [27]\n",
      " [ 2]\n",
      " [12]\n",
      " [36]\n",
      " [27]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [20]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [14]\n",
      " [ 3]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [23]\n",
      " [36]\n",
      " [36]\n",
      " [34]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [34]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [12]\n",
      " [ 1]\n",
      " [ 8]\n",
      " [13]\n",
      " [ 1]\n",
      " [20]\n",
      " [36]\n",
      " [23]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [29]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [37]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [34]\n",
      " [ 5]\n",
      " [36]\n",
      " [34]\n",
      " [ 7]\n",
      " [36]\n",
      " [36]\n",
      " [30]\n",
      " [20]\n",
      " [36]\n",
      " [10]\n",
      " [ 6]\n",
      " [10]\n",
      " [20]\n",
      " [36]\n",
      " [18]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [13]\n",
      " [21]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [13]\n",
      " [36]\n",
      " [27]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [23]\n",
      " [ 6]\n",
      " [18]\n",
      " [ 2]\n",
      " [12]\n",
      " [17]\n",
      " [27]\n",
      " [36]\n",
      " [27]\n",
      " [27]\n",
      " [27]\n",
      " [ 4]\n",
      " [ 9]\n",
      " [14]\n",
      " [ 4]\n",
      " [19]\n",
      " [ 3]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [23]\n",
      " [ 0]\n",
      " [17]\n",
      " [36]\n",
      " [34]\n",
      " [34]\n",
      " [ 1]\n",
      " [ 8]\n",
      " [20]\n",
      " [ 1]\n",
      " [30]\n",
      " [20]\n",
      " [36]\n",
      " [36]\n",
      " [ 0]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [29]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [19]]\n"
     ]
    }
   ],
   "source": [
    "print(pred[1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./data/bridge_model_back12_800000.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_251_input to have shape (69,) but got array with shape (97,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-b97274ecbb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombats_train_hot_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_251_input to have shape (69,) but got array with shape (97,)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(train_norm, combats_train_hot_label, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "plt.plot(record.history['acc'],label='acc')\n",
    "plt.plot(record.history['val_acc'],label='val_acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(record.history['loss'],label='loss')\n",
    "plt.plot(record.history['val_loss'],label='val_loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import csv\n",
    "bridge_df_test = []\n",
    "\n",
    "bridge_df_test = pd.concat([bridge_dfN_test, bridge_dfS_test], ignore_index=True)\n",
    "bridge_df_test = pd.concat([bridge_df_test, bridge_dfE_test], ignore_index=True)\n",
    "bridge_df_test = pd.concat([bridge_df_test, bridge_dfW_test], ignore_index=True)\n",
    "\n",
    "bridge_df_test.to_csv(\"bridge_test\", encoding='utf-8', index=False)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "(20000, 19)\n",
      "(56666, 97)\n",
      "(56666, 69)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('bridge_test.csv') \n",
    "#test_df = test_df[:20000]\n",
    "\n",
    "\n",
    "print(len(test_df.iloc[:,:]))\n",
    "print(test_df.iloc[:,:].shape)\n",
    "#print(test_df)\n",
    "\n",
    "test_data=[]\n",
    "test_data_without_feature = []\n",
    "\n",
    "for i in range(len(test_df.iloc[:,:])):\n",
    "    if test_df.iloc[i,1] == 'none':\n",
    "        test_df.iloc[i,1] = 0\n",
    "    elif test_df.iloc[i,1] == 'NS':\n",
    "        test_df.iloc[i,1] = 1\n",
    "    elif test_df.iloc[i,1] == 'EW':\n",
    "        test_df.iloc[i,1] = 2\n",
    "    elif test_df.iloc[i,1] == 'both':\n",
    "        test_df.iloc[i,1] = 3\n",
    "        \n",
    "    temp_list = []\n",
    "    without_feature = []\n",
    "    temp_list.append(bridge_df.iloc[i,0])\n",
    "    without_feature.append(bridge_df.iloc[i,0])\n",
    "    temp_list.append(bridge_df.iloc[i,1])\n",
    "    without_feature.append(bridge_df.iloc[i,1])\n",
    "    temp_list.append(bridge_df.iloc[i,2])\n",
    "    without_feature.append(bridge_df.iloc[i,2])\n",
    "    temp_list.append(bridge_df.iloc[i,3])\n",
    "    without_feature.append(bridge_df.iloc[i,3])\n",
    "    temp_list.append(bridge_df.iloc[i,5])\n",
    "    without_feature.append(bridge_df.iloc[i,5])\n",
    "\n",
    "    split_list6 = test_df.iloc[i,6].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list6[j])\n",
    "    '''\n",
    "    split_list7 = test_df.iloc[i,7].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list7[j])\n",
    "    '''\n",
    "    split_list9 = test_df.iloc[i,9].split('|')    \n",
    "    for j in range(4):\n",
    "        suit = [0]*13\n",
    "        for k in range(len(split_list9[j])):\n",
    "            if split_list9[j][k] == 'A':\n",
    "                suit[1] = 1\n",
    "            elif split_list9[j][k] == 'K':\n",
    "                suit[0] = 1\n",
    "            elif split_list9[j][k] == 'Q':\n",
    "                suit[12] = 1\n",
    "            elif split_list9[j][k] == 'J':\n",
    "                suit[11] = 1\n",
    "            elif split_list9[j][k] == 'T':\n",
    "                suit[10] = 1\n",
    "            elif split_list9[j][k].isdigit():\n",
    "                suit[int(split_list9[j][k])] = 1\n",
    "            else:\n",
    "                suit[k] = -1\n",
    "        without_feature = without_feature + suit\n",
    "        temp_list = temp_list + suit\n",
    "        \n",
    "    split_list10 = test_df.iloc[i,10].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list10[j])\n",
    "    temp_list.append(test_df.iloc[i,11])\n",
    "    \n",
    "    split_list12 = test_df.iloc[i,12].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list12[j])\n",
    "    split_list13 = test_df.iloc[i,13].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list13[j])\n",
    "    split_list14 = test_df.iloc[i,14].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list14[j])\n",
    "    split_list15 = test_df.iloc[i,15].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list15[j])\n",
    "    \n",
    "    temp_list.append(test_df.iloc[i,16])\n",
    "    temp_list.append(test_df.iloc[i,17])\n",
    "    if(test_df.iloc[i,18] == 'N'):\n",
    "        temp_list.append(0)\n",
    "    elif(test_df.iloc[i,18] == 'S'):\n",
    "        temp_list.append(1)\n",
    "    elif(test_df.iloc[i,18] == 'E'):\n",
    "        temp_list.append(2)\n",
    "    elif(test_df.iloc[i,18] == 'W'):\n",
    "        temp_list.append(3)\n",
    "    else:\n",
    "        temp_list.append(-1)        \n",
    "              \n",
    "    order = test_df.iloc[i,5]    \n",
    "    split_list = test_df.iloc[i,4].split('|')\n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence    \n",
    "\n",
    "    for ex in range(add_bidding):\n",
    "        temp = 0\n",
    "        temp_list_bidding =[-1]*12\n",
    "        end_1 = ex*4 + order - 1 # split_list[end_1] is the bidding choice of this player in this round \n",
    "        #print('end_1: ', end_1)\n",
    "        #lenth_1 = len(split_list)-1\n",
    "        for j in range(end_1):\n",
    "            if(j>11):\n",
    "                break\n",
    "            split_list[end_1-j-1] = split_list[end_1-j-1].replace(\"!\", \"\")\n",
    "            #print(split_list[end_1-j-1])\n",
    "            if(split_list[end_1-j-1][0]=='p' or split_list[end_1-j-1][0]=='P'):\n",
    "                temp_list_bidding[11-j]=0\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='d' or split_list[end_1-j-1][0]=='D'):\n",
    "                temp_list_bidding[11-j]=36\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='r' or split_list[end_1-j-1][0]=='R'):\n",
    "                temp_list_bidding[11-j]=37\n",
    "                continue\n",
    "\n",
    "\n",
    "            temp = 0\n",
    "            if(len(split_list[end_1-j-1]) != 2):\n",
    "                temp = -1\n",
    "                break\n",
    "            if(split_list[end_1-j-1][0].isdigit()):\n",
    "                temp += (int(split_list[end_1-j-1][0])-1)*5\n",
    "            if(split_list[end_1-j-1][1] == 'C' or split_list[end_1-j-1][1] == 'c'):\n",
    "                temp += 1\n",
    "            elif(split_list[end_1-j-1][1] == 'D' or split_list[end_1-j-1][1] == 'd' ):\n",
    "                temp += 2\n",
    "            elif(split_list[end_1-j-1][1] == 'H' or split_list[end_1-j-1][1] == 'h'):\n",
    "                temp += 3\n",
    "            elif(split_list[end_1-j-1][1] == 'S' or split_list[end_1-j-1][1] == 's'):\n",
    "                temp += 4\n",
    "            elif(split_list[end_1-j-1][1] == 'N' or split_list[end_1-j-1][1] == 'n'):\n",
    "                temp += 5\n",
    "            else:\n",
    "                temp = -1\n",
    "                break\n",
    "            temp_list_bidding[11-j] = temp\n",
    "            \n",
    "        example = temp_list.copy()\n",
    "        example_without_fea =  without_feature.copy()\n",
    "        for j in range(12):\n",
    "            example.append(temp_list_bidding[j])\n",
    "            example_without_fea.append(temp_list_bidding[j])\n",
    "        test_data.append(example)\n",
    "        test_data_without_feature.append(example_without_fea)\n",
    "\n",
    "test_data = np.asarray(test_data)\n",
    "test_data_without_feature = np.asarray(test_data_without_feature)\n",
    "test_data = test_data.astype('float')\n",
    "test_data_without_feature = test_data_without_feature.astype('float')\n",
    "print(test_data.shape)\n",
    "print(test_data_without_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.  2.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[ 9.  2.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1.  4.  0. 10.  0.]\n",
      "[ 9.  2.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0. -1. -1. -1. -1.  4.  0. 10.  0. 11.  0. 19.  0.]\n",
      "[[ 1.  0.  0. ...  4.  0.  7.]\n",
      " [ 1.  0.  0. ...  8.  0. 10.]\n",
      " [ 1.  0.  0. ... 15.  0. 17.]\n",
      " ...\n",
      " [24.  0.  0. ... -1. -1.  4.]\n",
      " [24.  0.  0. ... 10.  0. 11.]\n",
      " [24.  0.  0. ... 19.  0.  0.]]\n",
      "(56666, 69)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_without_feature[28335])\n",
    "print(test_data_without_feature[28336])\n",
    "print(test_data_without_feature[28337])\n",
    "print(test_data_without_feature)\n",
    "print(test_data_without_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  4.  0.  7.]\n",
      " [ 1.  0.  0. ...  8.  0. 10.]\n",
      " [ 1.  0.  0. ... 15.  0. 17.]\n",
      " ...\n",
      " [24.  0.  0. ... -1. -1.  4.]\n",
      " [24.  0.  0. ... 10.  0. 11.]\n",
      " [24.  0.  0. ... 19.  0.  0.]] [[ 0.10599979  0.          0.         ...  0.42399915  0.\n",
      "   0.74199852]\n",
      " [ 0.06337243  0.          0.         ...  0.5069794   0.\n",
      "   0.63372425]\n",
      " [ 0.0362977   0.          0.         ...  0.54446551  0.\n",
      "   0.61706091]\n",
      " ...\n",
      " [ 0.96386319  0.          0.         ... -0.04016097 -0.04016097\n",
      "   0.16064387]\n",
      " [ 0.82956136  0.          0.         ...  0.34565056  0.\n",
      "   0.38021562]\n",
      " [ 0.6945589   0.          0.         ...  0.54985913  0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#ttt = np.append(traintest_data)\n",
    "#avoid_data = test_data\n",
    "#test_norm = normalizer.transform(test_data)\n",
    "test_without_feature_norm = normalizer.transform(test_data_without_feature)\n",
    "print(test_data_without_feature, test_without_feature_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make testing data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "56666\n"
     ]
    }
   ],
   "source": [
    "combats_test_hot_label = [[0 for x in range(38)] for y in range(len(test_data))]\n",
    "print(type(combats_test_hot_label))\n",
    "t = 0\n",
    "\n",
    "for i in range(len(test_df.iloc[:,:])):\n",
    "    split_list = test_df.iloc[i,4].split('|')\n",
    "    order = test_df.iloc[i,5]\n",
    "    \n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence\n",
    "    #print('len:', len(split_list), 'order', order)\n",
    "    #if(order+1>len(split_list)):\n",
    "        #combats_train_hot_label[i][35] = 1\n",
    "        #continue\n",
    "        \n",
    "    for ex in range(add_bidding):\n",
    "        end_1 = ex*4 + order - 1\n",
    "        #print(end_1)\n",
    "        split_list[end_1] = split_list[end_1].replace(\"!\", \"\")\n",
    "        if(split_list[end_1]=='p' or split_list[end_1]=='p!' or split_list[end_1]=='P' or split_list[end_1]=='P!'):\n",
    "            combats_test_hot_label[t][0] = 1\n",
    "\n",
    "        elif(split_list[end_1]=='d' or split_list[end_1]=='d!' or split_list[end_1]=='D' or split_list[end_1]=='D!'):\n",
    "            combats_test_hot_label[t][36] = 1\n",
    "        elif(split_list[end_1]=='r' or split_list[end_1]=='r!' or split_list[end_1]=='R' or split_list[end_1]=='R!'):\n",
    "            combats_test_hot_label[t][37] = 1\n",
    "        temp_num = 0    \n",
    "        if (len(split_list[end_1]) == 2 and split_list[end_1][0].isdigit()):\n",
    "            temp_num = (int(split_list[end_1][0])-1)*5\n",
    "            if(split_list[end_1][1] == 'C' or split_list[end_1][1] == 'c'):\n",
    "                temp_num += 1\n",
    "            elif(split_list[end_1][1] == 'D' or split_list[end_1][1] == 'd' ):\n",
    "                temp_num += 2\n",
    "            elif(split_list[end_1][1] == 'H' or split_list[end_1][1] == 'h'):\n",
    "                temp_num += 3\n",
    "            elif(split_list[end_1][1] == 'S' or split_list[end_1][1] == 's'):\n",
    "                temp_num += 4\n",
    "            elif(split_list[end_1][1] == 'N' or split_list[end_1][1] == 'n'): \n",
    "                temp_num += 5\n",
    "            else:\n",
    "                temp_num = 0\n",
    "            combats_test_hot_label[t][temp_num] = 1 \n",
    "        t += 1\n",
    "    \n",
    "\n",
    "#combats_train_hot_label = np_utils.to_categorical(combats_train_label,2)\n",
    "\n",
    "combats_test_hot_label = np.asarray(combats_test_hot_label)\n",
    "#combats_test_hot_label = combats_test_hot_label.astype(float)\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(combats_test_hot_label[28335])\n",
    "print(combats_test_hot_label[28336])\n",
    "print(combats_test_hot_label[28337])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data[:,0] = test_data[:,0]/50\n",
    "test_data[:,1] = test_data[:,1]/3\n",
    "test_data[:,4:15] = test_data[:,4:15]/37\n",
    "test_data[:,16] = test_data[:,16]/4\n",
    "test_data[:,17:20] = test_data[:,17:20]/13\n",
    "test_data[:,73:76] = test_data[:,73:76]/13\n",
    "test_data[:,81] = test_data[:,81]/30\n",
    "test_data[:,91:94] = test_data[:,91:94]/10\n",
    "test_data[:,95] = test_data[:,95]/10\n",
    "test_data[:,96] = test_data[:,96]/10\n",
    "\n",
    "\n",
    "print(test_data.shape)\n",
    "print(type(test_data))\n",
    "print(test_data[0,:])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.asarray(output)\n",
    "test_data = np.asarray(test_data)\n",
    "predicted_output_df = np.asarray(predicted_output_df)\n",
    "\n",
    "temp = [[0 for x in range(38)] for y in range(20000)]\n",
    "\n",
    "for i in range(len(output)):\n",
    "    temp[i][int(output[i])] = 1\n",
    "\n",
    "\n",
    "\n",
    "score= model.evaluate(test_data, ground[:19999], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the result to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv',index_label = \"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 317,
   "position": {
    "height": "229px",
    "left": "1293px",
    "right": "20px",
    "top": "156px",
    "width": "623px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
